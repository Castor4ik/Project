{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Копия блокнота \"Копия блокнота \"KR 1 Bobrov EK-51.ipynb\"\"",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zu_L3ks9WbrA"
      },
      "source": [
        "#импорт основных библиотек\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yAZ-jvDZzXf",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6bc0feb6-881c-4b60-f1b6-bb808448ee0c"
      },
      "source": [
        "#импорт датасета\n",
        "\n",
        "from google.colab import files \n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cbbecd89-c18e-4c3e-8b06-f769e89844dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cbbecd89-c18e-4c3e-8b06-f769e89844dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving listings_prepar.csv to listings_prepar.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "x_xAcF7jWbrC",
        "outputId": "2788d4a8-d4e3-4f18-b602-ff7cc12fbb8e"
      },
      "source": [
        "#начальный вид датасета\n",
        "\n",
        "df = pd.read_csv('listings_prepar.csv')\n",
        "df"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>calculated_host_listings_count</th>\n",
              "      <th>availability_365</th>\n",
              "      <th>datetime_diff</th>\n",
              "      <th>room_type=0</th>\n",
              "      <th>room_type=1</th>\n",
              "      <th>room_type=2</th>\n",
              "      <th>room_type=3</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>831.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>1247.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>115.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1658.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>38.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>890.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3839</th>\n",
              "      <td>19.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>889.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>169.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3840</th>\n",
              "      <td>40.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>922.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>149.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3841</th>\n",
              "      <td>14.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>879.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842</th>\n",
              "      <td>73.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>822.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3843</th>\n",
              "      <td>74.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>824.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3844 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      number_of_reviews  calculated_host_listings_count  ...  room_type=3  price\n",
              "0                  65.0                             1.0  ...          0.0   70.0\n",
              "1                  33.0                             2.0  ...          0.0   17.0\n",
              "2                  64.0                             1.0  ...          0.0  115.0\n",
              "3                   8.0                             1.0  ...          0.0   54.0\n",
              "4                  38.0                             3.0  ...          0.0   90.0\n",
              "...                 ...                             ...  ...          ...    ...\n",
              "3839               19.0                             2.0  ...          0.0  169.0\n",
              "3840               40.0                             8.0  ...          1.0  149.0\n",
              "3841               14.0                             1.0  ...          0.0   80.0\n",
              "3842               73.0                             2.0  ...          0.0  180.0\n",
              "3843               74.0                             3.0  ...          0.0   25.0\n",
              "\n",
              "[3844 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DID6ilAWbrR"
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "X = df.iloc[:, :-1]\n",
        "y = df['price']\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afwMGHYzWbrT"
      },
      "source": [
        "#меняем формат массивов на датасеты\n",
        "\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_test = pd.DataFrame(X_test)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "y_train = pd.DataFrame(y_train)\n",
        "y_train = np.asarray(y_train).reshape(-1,1)\n",
        "y_test = np.asarray(y_test).reshape(-1,1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev-AHxcrWbrT"
      },
      "source": [
        "# Шкалируем данные \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler().fit(X_train)\n",
        "X_train = sc_X.transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "sc_y = StandardScaler().fit(y_train)\n",
        "y_train = sc_y.transform(y_train)\n",
        "y_test = sc_y.transform(y_test)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1HRzy5fWbrU"
      },
      "source": [
        "#устанавливаем нужные библиотеки для НС\n",
        "\n",
        "#!pip install tensorflow\n",
        "#!pip install keras\n",
        "# Importing the Keras libraries and packages\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baqR6bjZWbrU"
      },
      "source": [
        "\n",
        "# Initialising the ANN\n",
        "rnn = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "rnn.add(Dense(12, activation = 'tanh', input_dim = 8))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "rnn.add(Dense(7, activation = 'tanh'))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "rnn.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "# Compiling the ANN\n",
        "rnn.compile(optimizer='adam', loss='mean_squared_error', metrics = ['accuracy'])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzHuFlZkXZsO",
        "outputId": "ff01b48b-cc50-434a-e9e0-de40da44356b"
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "k = rnn.fit(X_train, y_train, batch_size = 8, validation_data=(X_test, y_test), epochs = 100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 1.0515 - accuracy: 0.0000e+00 - val_loss: 0.9720 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9793 - accuracy: 0.0000e+00 - val_loss: 0.9715 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9720 - accuracy: 0.0000e+00 - val_loss: 0.9600 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9658 - accuracy: 0.0000e+00 - val_loss: 0.9569 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9618 - accuracy: 0.0000e+00 - val_loss: 0.9502 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9581 - accuracy: 0.0000e+00 - val_loss: 0.9515 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9552 - accuracy: 0.0000e+00 - val_loss: 0.9469 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9524 - accuracy: 0.0000e+00 - val_loss: 0.9517 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9508 - accuracy: 0.0000e+00 - val_loss: 0.9637 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9484 - accuracy: 0.0000e+00 - val_loss: 0.9504 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9478 - accuracy: 0.0000e+00 - val_loss: 0.9464 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9453 - accuracy: 0.0000e+00 - val_loss: 0.9520 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9449 - accuracy: 0.0000e+00 - val_loss: 0.9475 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9446 - accuracy: 0.0000e+00 - val_loss: 0.9438 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9431 - accuracy: 0.0000e+00 - val_loss: 0.9508 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9390 - accuracy: 0.0000e+00 - val_loss: 0.9483 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9395 - accuracy: 0.0000e+00 - val_loss: 0.9438 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9390 - accuracy: 0.0000e+00 - val_loss: 0.9555 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9389 - accuracy: 0.0000e+00 - val_loss: 0.9464 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9370 - accuracy: 0.0000e+00 - val_loss: 0.9516 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9374 - accuracy: 0.0000e+00 - val_loss: 0.9499 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9351 - accuracy: 0.0000e+00 - val_loss: 0.9629 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9323 - accuracy: 0.0000e+00 - val_loss: 0.9598 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9338 - accuracy: 0.0000e+00 - val_loss: 0.9404 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9310 - accuracy: 0.0000e+00 - val_loss: 0.9448 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9325 - accuracy: 0.0000e+00 - val_loss: 0.9455 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9310 - accuracy: 0.0000e+00 - val_loss: 0.9411 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9331 - accuracy: 0.0000e+00 - val_loss: 0.9423 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9294 - accuracy: 0.0000e+00 - val_loss: 0.9351 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9271 - accuracy: 0.0000e+00 - val_loss: 0.9605 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9258 - accuracy: 0.0000e+00 - val_loss: 0.9367 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9272 - accuracy: 0.0000e+00 - val_loss: 0.9430 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9253 - accuracy: 0.0000e+00 - val_loss: 0.9465 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9252 - accuracy: 0.0000e+00 - val_loss: 0.9405 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9248 - accuracy: 0.0000e+00 - val_loss: 0.9490 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9229 - accuracy: 0.0000e+00 - val_loss: 0.9413 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9221 - accuracy: 0.0000e+00 - val_loss: 0.9507 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9237 - accuracy: 0.0000e+00 - val_loss: 0.9361 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9213 - accuracy: 0.0000e+00 - val_loss: 0.9372 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9207 - accuracy: 0.0000e+00 - val_loss: 0.9495 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9204 - accuracy: 0.0000e+00 - val_loss: 0.9345 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9197 - accuracy: 0.0000e+00 - val_loss: 0.9415 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9214 - accuracy: 0.0000e+00 - val_loss: 0.9378 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9197 - accuracy: 0.0000e+00 - val_loss: 0.9332 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9159 - accuracy: 0.0000e+00 - val_loss: 0.9365 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9160 - accuracy: 0.0000e+00 - val_loss: 0.9381 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9153 - accuracy: 0.0000e+00 - val_loss: 0.9332 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9181 - accuracy: 0.0000e+00 - val_loss: 0.9316 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9156 - accuracy: 0.0000e+00 - val_loss: 0.9369 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9161 - accuracy: 0.0000e+00 - val_loss: 0.9317 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9151 - accuracy: 0.0000e+00 - val_loss: 0.9385 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9143 - accuracy: 0.0000e+00 - val_loss: 0.9382 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9147 - accuracy: 0.0000e+00 - val_loss: 0.9447 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9128 - accuracy: 0.0000e+00 - val_loss: 0.9396 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9122 - accuracy: 0.0000e+00 - val_loss: 0.9487 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9137 - accuracy: 0.0000e+00 - val_loss: 0.9296 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9096 - accuracy: 0.0000e+00 - val_loss: 0.9368 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9102 - accuracy: 0.0000e+00 - val_loss: 0.9459 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9107 - accuracy: 0.0000e+00 - val_loss: 0.9315 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9103 - accuracy: 0.0000e+00 - val_loss: 0.9339 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9089 - accuracy: 0.0000e+00 - val_loss: 0.9308 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9103 - accuracy: 0.0000e+00 - val_loss: 0.9347 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9095 - accuracy: 0.0000e+00 - val_loss: 0.9364 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9095 - accuracy: 0.0000e+00 - val_loss: 0.9289 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9073 - accuracy: 0.0000e+00 - val_loss: 0.9355 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9075 - accuracy: 0.0000e+00 - val_loss: 0.9466 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9070 - accuracy: 0.0000e+00 - val_loss: 0.9369 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9061 - accuracy: 0.0000e+00 - val_loss: 0.9364 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9038 - accuracy: 0.0000e+00 - val_loss: 0.9480 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9066 - accuracy: 0.0000e+00 - val_loss: 0.9376 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9032 - accuracy: 0.0000e+00 - val_loss: 0.9371 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9049 - accuracy: 0.0000e+00 - val_loss: 0.9479 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9051 - accuracy: 0.0000e+00 - val_loss: 0.9401 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9045 - accuracy: 0.0000e+00 - val_loss: 0.9421 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9040 - accuracy: 0.0000e+00 - val_loss: 0.9424 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9008 - accuracy: 0.0000e+00 - val_loss: 0.9341 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9030 - accuracy: 0.0000e+00 - val_loss: 0.9435 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9011 - accuracy: 0.0000e+00 - val_loss: 0.9403 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9028 - accuracy: 0.0000e+00 - val_loss: 0.9435 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9016 - accuracy: 0.0000e+00 - val_loss: 0.9405 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8997 - accuracy: 0.0000e+00 - val_loss: 0.9463 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.9002 - accuracy: 0.0000e+00 - val_loss: 0.9367 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8990 - accuracy: 0.0000e+00 - val_loss: 0.9418 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8997 - accuracy: 0.0000e+00 - val_loss: 0.9418 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8992 - accuracy: 0.0000e+00 - val_loss: 0.9472 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8997 - accuracy: 0.0000e+00 - val_loss: 0.9456 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8995 - accuracy: 0.0000e+00 - val_loss: 0.9376 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8984 - accuracy: 0.0000e+00 - val_loss: 0.9418 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8967 - accuracy: 0.0000e+00 - val_loss: 0.9467 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8987 - accuracy: 0.0000e+00 - val_loss: 0.9523 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8979 - accuracy: 0.0000e+00 - val_loss: 0.9424 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8975 - accuracy: 0.0000e+00 - val_loss: 0.9386 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8960 - accuracy: 0.0000e+00 - val_loss: 0.9485 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8945 - accuracy: 0.0000e+00 - val_loss: 0.9535 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8978 - accuracy: 0.0000e+00 - val_loss: 0.9434 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8941 - accuracy: 0.0000e+00 - val_loss: 0.9460 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8950 - accuracy: 0.0000e+00 - val_loss: 0.9492 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8947 - accuracy: 0.0000e+00 - val_loss: 0.9451 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8935 - accuracy: 0.0000e+00 - val_loss: 0.9428 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "385/385 [==============================] - 1s 2ms/step - loss: 0.8938 - accuracy: 0.0000e+00 - val_loss: 0.9583 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S3lGFehXcr7"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = rnn.predict(X_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zpUK-QSG41jL",
        "outputId": "750850bb-3250-40f2-fded-59d50172d2f8"
      },
      "source": [
        "# Plotting loss & accuracy\n",
        "plt.figure()\n",
        "plt.plot(k.history['loss'])\n",
        "plt.plot(k.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amDrU1TQ6fmS"
      },
      "source": [
        "#Стоит отметить, что на примерно 40-80 эпохах у нас практически нет никакого разрыва! Попробуем построить, возьмем 80 эпох."
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9nA73WueZfI"
      },
      "source": [
        "# Inversing scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "y_hat = sc_y.inverse_transform(y_pred)\n",
        "y_test = sc_y.inverse_transform(y_test)\n",
        "X_test = sc_X.inverse_transform(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eCAA13web3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9666897-13bb-419c-81d4-ae409327d890"
      },
      "source": [
        "# Mean squared error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(sc_y.inverse_transform(y_train), sc_y.inverse_transform(rnn.predict(X_train)), squared=False).round(3), mean_squared_error(y_test, y_hat, squared=False).round(3)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35.165, 36.493)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL0OGGVL4R50"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYatQ78gedsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "6bb1870e-8285-4cb9-ab35-292dc3a689ef"
      },
      "source": [
        "#testing the best features\n",
        "\n",
        "df = df.drop(columns = ['datetime_diff'], );\n",
        "df = df.drop(columns = ['calculated_host_listings_count'], );\n",
        "df = df.drop(columns = ['availability_365'], );\n",
        "df = df.drop(columns = ['room_type=0'], );\n",
        "df = df.drop(columns = ['room_type=1'], );\n",
        "df = df.drop(columns = ['room_type=2'], );\n",
        "df = df.drop(columns = ['room_type=3'], );\n",
        "df\n",
        "\t\t\t\t\t\t\t\t"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_of_reviews</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65.0</td>\n",
              "      <td>70.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64.0</td>\n",
              "      <td>115.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.0</td>\n",
              "      <td>54.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>38.0</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3839</th>\n",
              "      <td>19.0</td>\n",
              "      <td>169.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3840</th>\n",
              "      <td>40.0</td>\n",
              "      <td>149.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3841</th>\n",
              "      <td>14.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842</th>\n",
              "      <td>73.0</td>\n",
              "      <td>180.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3843</th>\n",
              "      <td>74.0</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3844 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      number_of_reviews  price\n",
              "0                  65.0   70.0\n",
              "1                  33.0   17.0\n",
              "2                  64.0  115.0\n",
              "3                   8.0   54.0\n",
              "4                  38.0   90.0\n",
              "...                 ...    ...\n",
              "3839               19.0  169.0\n",
              "3840               40.0  149.0\n",
              "3841               14.0   80.0\n",
              "3842               73.0  180.0\n",
              "3843               74.0   25.0\n",
              "\n",
              "[3844 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCbmmlVGqxOS"
      },
      "source": [
        "# Initialising the ANN\n",
        "rnn = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "rnn.add(Dense(12, activation = 'tanh', input_dim = 8))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "rnn.add(Dense(7, activation = 'tanh'))\n",
        "\n",
        "\n",
        "# Adding the output layer\n",
        "rnn.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "# Compiling the ANN\n",
        "rnn.compile(optimizer='adam', loss='mean_squared_error', metrics = ['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S46rejQUrrJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de593aa3-a4b6-48e1-e4f7-63df46a3602b"
      },
      "source": [
        "# Fitting the ANN to the Training set\n",
        "k = rnn.fit(X_train, y_train, batch_size = 10, validation_data=(X_test, y_test), epochs = 80)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "308/308 [==============================] - 1s 3ms/step - loss: 1.0432 - accuracy: 0.0000e+00 - val_loss: 5288.5801 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9834 - accuracy: 0.0000e+00 - val_loss: 5285.3101 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9723 - accuracy: 0.0000e+00 - val_loss: 5292.4087 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9661 - accuracy: 0.0000e+00 - val_loss: 5282.3853 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9630 - accuracy: 0.0000e+00 - val_loss: 5285.2686 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9599 - accuracy: 0.0000e+00 - val_loss: 5295.8936 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9571 - accuracy: 0.0000e+00 - val_loss: 5291.8833 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9544 - accuracy: 0.0000e+00 - val_loss: 5321.7593 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9517 - accuracy: 0.0000e+00 - val_loss: 5321.9897 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9513 - accuracy: 0.0000e+00 - val_loss: 5315.9395 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9473 - accuracy: 0.0000e+00 - val_loss: 5311.7866 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9446 - accuracy: 0.0000e+00 - val_loss: 5337.0317 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9441 - accuracy: 0.0000e+00 - val_loss: 5339.1245 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9423 - accuracy: 0.0000e+00 - val_loss: 5324.4102 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9403 - accuracy: 0.0000e+00 - val_loss: 5320.4282 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9379 - accuracy: 0.0000e+00 - val_loss: 5304.7505 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9351 - accuracy: 0.0000e+00 - val_loss: 5278.7935 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9341 - accuracy: 0.0000e+00 - val_loss: 5280.0083 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9330 - accuracy: 0.0000e+00 - val_loss: 5273.0894 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9320 - accuracy: 0.0000e+00 - val_loss: 5267.4229 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9314 - accuracy: 0.0000e+00 - val_loss: 5262.3428 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9295 - accuracy: 0.0000e+00 - val_loss: 5272.8760 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9282 - accuracy: 0.0000e+00 - val_loss: 5256.2017 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9268 - accuracy: 0.0000e+00 - val_loss: 5250.6357 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9267 - accuracy: 0.0000e+00 - val_loss: 5241.5078 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9266 - accuracy: 0.0000e+00 - val_loss: 5259.0957 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9241 - accuracy: 0.0000e+00 - val_loss: 5255.8340 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9232 - accuracy: 0.0000e+00 - val_loss: 5263.5718 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9237 - accuracy: 0.0000e+00 - val_loss: 5263.7739 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9234 - accuracy: 0.0000e+00 - val_loss: 5265.2993 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9206 - accuracy: 0.0000e+00 - val_loss: 5264.9131 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9204 - accuracy: 0.0000e+00 - val_loss: 5260.6978 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9196 - accuracy: 0.0000e+00 - val_loss: 5256.4272 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9204 - accuracy: 0.0000e+00 - val_loss: 5253.7705 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9182 - accuracy: 0.0000e+00 - val_loss: 5261.0469 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9180 - accuracy: 0.0000e+00 - val_loss: 5250.1445 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9166 - accuracy: 0.0000e+00 - val_loss: 5253.7720 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9177 - accuracy: 0.0000e+00 - val_loss: 5250.6265 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9156 - accuracy: 0.0000e+00 - val_loss: 5250.0791 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9171 - accuracy: 0.0000e+00 - val_loss: 5254.4048 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9142 - accuracy: 0.0000e+00 - val_loss: 5255.2061 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9148 - accuracy: 0.0000e+00 - val_loss: 5242.8062 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9137 - accuracy: 0.0000e+00 - val_loss: 5243.4893 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9136 - accuracy: 0.0000e+00 - val_loss: 5244.3477 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9120 - accuracy: 0.0000e+00 - val_loss: 5240.8745 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9113 - accuracy: 0.0000e+00 - val_loss: 5246.1182 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9116 - accuracy: 0.0000e+00 - val_loss: 5242.0068 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9111 - accuracy: 0.0000e+00 - val_loss: 5240.9224 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9107 - accuracy: 0.0000e+00 - val_loss: 5245.3252 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9095 - accuracy: 0.0000e+00 - val_loss: 5245.0479 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9097 - accuracy: 0.0000e+00 - val_loss: 5248.9175 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9075 - accuracy: 0.0000e+00 - val_loss: 5244.5352 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9088 - accuracy: 0.0000e+00 - val_loss: 5248.4673 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9081 - accuracy: 0.0000e+00 - val_loss: 5245.6553 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9082 - accuracy: 0.0000e+00 - val_loss: 5240.9956 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9069 - accuracy: 0.0000e+00 - val_loss: 5248.9004 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9053 - accuracy: 0.0000e+00 - val_loss: 5235.6846 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9063 - accuracy: 0.0000e+00 - val_loss: 5243.8438 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9070 - accuracy: 0.0000e+00 - val_loss: 5234.7808 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9042 - accuracy: 0.0000e+00 - val_loss: 5223.3423 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9052 - accuracy: 0.0000e+00 - val_loss: 5242.3979 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9064 - accuracy: 0.0000e+00 - val_loss: 5228.7661 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9048 - accuracy: 0.0000e+00 - val_loss: 5224.3652 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9036 - accuracy: 0.0000e+00 - val_loss: 5225.9390 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9045 - accuracy: 0.0000e+00 - val_loss: 5229.1177 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9028 - accuracy: 0.0000e+00 - val_loss: 5230.1152 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9029 - accuracy: 0.0000e+00 - val_loss: 5216.3232 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9004 - accuracy: 0.0000e+00 - val_loss: 5217.5576 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9026 - accuracy: 0.0000e+00 - val_loss: 5217.4268 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9011 - accuracy: 0.0000e+00 - val_loss: 5221.0601 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9014 - accuracy: 0.0000e+00 - val_loss: 5220.4946 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.9007 - accuracy: 0.0000e+00 - val_loss: 5220.0020 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8998 - accuracy: 0.0000e+00 - val_loss: 5207.9653 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8987 - accuracy: 0.0000e+00 - val_loss: 5208.6538 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8999 - accuracy: 0.0000e+00 - val_loss: 5210.7847 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8961 - accuracy: 0.0000e+00 - val_loss: 5211.0059 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8992 - accuracy: 0.0000e+00 - val_loss: 5208.8296 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8989 - accuracy: 0.0000e+00 - val_loss: 5209.9409 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8952 - accuracy: 0.0000e+00 - val_loss: 5201.5459 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/80\n",
            "308/308 [==============================] - 1s 2ms/step - loss: 0.8985 - accuracy: 0.0000e+00 - val_loss: 5205.4248 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA7Xviwjrt85"
      },
      "source": [
        "# Predicting the Test set results\n",
        "y_pred = rnn.predict(X_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG5XPpd1rxEt"
      },
      "source": [
        "# Inversing scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "y_hat = sc_y.inverse_transform(y_pred)\n",
        "y_test = sc_y.inverse_transform(y_test)\n",
        "X_test = sc_X.inverse_transform(X_test)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7-8WLCYr13f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82c3aeaa-8205-4b7b-df12-d4b907c4fce7"
      },
      "source": [
        "# Mean squared error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(sc_y.inverse_transform(y_train), sc_y.inverse_transform(rnn.predict(X_train)), squared=False).round(3), mean_squared_error(y_test, y_hat, squared=False).round(3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35.18, 2689.509)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W-hmqNgr5OT"
      },
      "source": [
        "# В целом стоит заметить, что НС лучше справляются с прогнозированием, особенно даже по одному критерию - количеству отзывов у апартаментов\n",
        "# Однако есть предположение, что на новых и свежих данных с учетом специфики вероятность высокой эффективности модели невысока"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynxiRngj-P4i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}